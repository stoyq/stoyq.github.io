---
title: "Searching for Authentic Writing in a World of AI-Generated Text"
description: "Classifying Text with Machine Learning."
date: 2026-01-13
categories: [ai, chatgpt, text, classification]
image: ../images/detecting-ai-text-square.png
image-alt: 'Human vs. AI Text'
bibliography: references.bib
format:
  html:
    toc: false
    code-fold: false
---

![A human using a magnifying glass to distinguish between human-written and AI-generated text](../images/detecting-ai-text.png)

In the past year, the use of generative AI tools such as ChatGPT has exploded in popularity. ChatGPT can be used to help people write emails, essays, summaries, and creative stories almost instantly. With more people using such tools, more people are wanting more authentic text written by real humans. So an important question has come up: can we distinguish between human-written and AI-generated text? There is plenty of research done in this area by [@fraser2025detecting; @georgiou2025humanai;  @fiedler2025humans].

This project looks to answer that question using data science techniques. It is important to define the problem, because the term "AI-generated" means something different to different people. If a human uses AI to generate text (AI-assisted), does that still count as human-written? Should there be 3 different categories (human-written, AI-assisted, and AI-generated)? And if so, how much assistance can a human get from AI before the text is classified as AI-generated? For this project, we will keep it simple. We will compare text written completely by humans (unassisted by AI) with text written by AI (produced by generative tools such as ChatGPT).

To conduct this study, we will collect written samples from English speakers with different ages and educational backgrounds. Everyone will respond to the same prompt. Then we will also have ChatGPT respond to the same prompt. This way, we get two comparable sets of responses, and we know the ground truth.

After collecting all the text samples (from humans and ChatGPT), we will use data science techniques to identify whether the text is written by a human or AI. We can measure the accuracy of our technique by simply comparing it to the ground truth. We aim to improve the technique to correctly classify the text as human-written or AI-generated. Some of the things we can use in our classification methodology include looking for patterns in the text such as: sentence length, word frequency, complexity and diversity of grammar and vocabulary. When we look at multiple clues, they can start to reveal if the text is written by human or AI.

We use logistic regression for this task. Basically the patterns we are looking for are the weights, and they form a score between 0 and 1. Higher scores suggest the text is more likely generated by AI, while lower scores suggest more human writing. We can test how accurate our machine learning model is by seeing how many correct identifications it produced.

This project aims to see if machines can help us identify text written by AI or not. However it is important to consider that AI systems are constantly evolving, and introducing the "human touch" to artificially-generated text. Limitations of using machines to detect AI-generated text need to be explored as humans evolve their writing in response to AI writing.
